{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# pdstools version 3: Polars\n",
                "\n",
                "With the version 3 release of pdstools, the back-end of the libary has shifted to use [Polars](https://github.com/pola-rs/polars). Polars is a blazingly fast DataFrames library implemented in Rust using Apache Arrow Columnar Format as the memory model. This means faster analyses and a more robust API: both externally and internally within our library. However, it is not a minor change, and will change the way you interact with the library. This article goes over some of the most notable changes, and most importantly: best practices.\n",
                "\n",
                "First off:\n",
                "\n",
                "## Lazy execution graphs\n",
                "\n",
                "One of the, if not the single most powerful feature of Polars is its `lazy execution API`. This allows you to iteratively build up your query, have Polars optimise it for you, and only `collect` the data after your entire query. In practice, this means that all row-wise filters & column-wise selects are shifted right to whenever you read the file, and all computations are optimised further. Let's look at an example, and one close to home!\n",
                "\n",
                "If we simply read in the shipped CDHSample dataset, and pass in the keyword `import_strategy='lazy'`, it will allow us to demonstrate this effect. Note: by default the import strategy is `'eager'`. We'll get to that later."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbsphinx": "hidden"
            },
            "outputs": [],
            "source": [
                "# These lines are only for rendering in the docs, and are hidden through Jupyter tags\n",
                "# Do not run if you're running the notebook seperately\n",
                "\n",
                "import plotly.io as pio\n",
                "\n",
                "pio.renderers.default = \"notebook_connected\"\n",
                "\n",
                "import sys\n",
                "\n",
                "sys.path.append(\"../../../\")\n",
                "sys.path.append('../../python')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pdstools import datasets, ADMDatamart\n",
                "import polars as pl\n",
                "dm = datasets.CDHSample(import_strategy='lazy')\n",
                "dm"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you've used the previous version of pdstools, you've probably noticed nothing's changed. You still get the same `ADMDatamart` object. \n",
                "\n",
                "Try accessing the `modelData`, `predictorData` or `combinedData` property however, and things are different."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.modelData"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Not a dataframe - but a `NAIVE QUERY PLAN`. It's relatively intuitive, but you'd read this chart bottom-to-top: \n",
                "\n",
                "- We read the table, $\\pi$ `*/27;` (reading all columns out of the 27 available) and $\\sigma$ `-;` (no row-wise filters applied).\n",
                "- We then rename the columns by a predefined manner\n",
                "- Then we only keep 12 out of the 27 available columns\n",
                "- Change `[\"Issue\",\"Group\",\"Channel\",\"Direction\",\"Configuration\"]` to be categorical, `\"Performance\"` to numeric.\n",
                "- Transform `\"SnapshotTime\"` to datetime\n",
                "- Add `[\"SuccessRate\",\"Last_Positives\",\"Last_ResponseCount\"]` as columns.\n",
                "\n",
                "A sharp eye might already notice an inefficiency here. If we first read in all columns, then rename and then filter, can't we already infer which columns we need based on our predefined function, and filter when reading? Well - yes!\n",
                "\n",
                "This is the `naive` plan. If we call `.show_graph()`, we get the optimized version:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.modelData.show_graph()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "At first glance; not a huge change. However, note at the bottom we import $\\pi$ `12/27;`: we filter right when reading the file, and only read in 12 columns! This can make a big difference, especially because one column (`\"pyModelData\"`) is very big. \n",
                "\n",
                "Thus far, the $\\sigma$ symbol has been `-`. We can also change that: the $\\sigma$ symbol shows you which filters it applies on the rows when it's reading. For our example purpose, Let's say we're only interested in actions containing `Visa`. We can add that filter right to our execution plan!\n",
                "\n",
                "To tell Polars we're trying to filter on a `column`, we simply start our query with `pl.col(\"Name\")`. The `Name` column, containing the action names, is a string column. Therefore, to access `string`-based operations, we simply use `.str` to go to the `string namespace`. We want the string to `contain` `Visa`, therefore: `query=pl.col(\"Name\").str.contains(\"Visa\")`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm = datasets.CDHSample(\n",
                "    import_strategy=\"lazy\", query=pl.col(\"Name\").str.contains(\"Visa\")\n",
                ")\n",
                "dm.modelData.show_graph()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\"Okay, but how do we actually get to the data?\" - Simple! Just use `.collect()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.modelData.collect()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This table is very similar to Pandas tables, though there are some slight differences. The types are explicitly mentioned in the header, string values are in quotes, and long string values get cut off more agressively. Other than that, there's no real change! And if you still want to use pandas, just call `.to_pandas()` :)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.modelData.collect().to_pandas()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we don't just have modelData, there's also information about predictors. This is under the `predictorData` attribute, and it works the same way. Thirdly, we add a attribute called `combinedData`. `combinedData` is technically just an inner join between the model data and the predictor data on the model ID. Therefore, the model ID's we filter out of the models also propagate to the combined data. To give more insight into this join, we can now simply show the execution graph of it:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.combinedData"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "While a beautiful graph, it is quite a lot to digest. The left side of the chart should look very familiar, as should the right side. The 'middle' part is new: this is the execution part for the predictor data. Here we only parse `Performance` to be a float, parse the timezones, and add [\"BinPropensity\",\"BinAdjustedPropensity\"]. For both the model data and the predictor data we take the last snapshot only when combining them, which you can see right before the topmost inner join.\n",
                "\n",
                "Again, a sharp eye will notice quite some inefficiencies here. The newest issue is that we're now importing `modelData` twice, once to filter out model IDs not being in the filter criteria, and another time to join with the table. But remember, we're not in the optimized graph:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.combinedData.show_graph()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Pretty neat. Not only do we not import modelData twice, we cache it at a certain point in the execution graph so we can _use_ it twice. And we get all of this for free with Polars' optimization engine! Also remember, at this point, we've not even read in any data yet! We can even do profiling on this execution graph, but that's a challenge to figure out on your own :). We can easily show the gains in time using this method using our new `save_data` method though: this will save our data to disk in an efficient format, and gives us a fast way to benchmark."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "files_without_subset = datasets.CDHSample(\n",
                "    import_strategy=\"lazy\", subset=False\n",
                ").save_data()\n",
                "files_with_subset = datasets.CDHSample(\n",
                "    import_strategy=\"lazy\", query=pl.col(\"Name\").str.contains(\"Visa\")\n",
                ").save_data()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%timeit ADMDatamart(model_filename=files_without_subset[0], predictor_filename=files_without_subset[1], import_strategy='lazy').combinedData.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%timeit ADMDatamart(model_filename=files_with_subset[0], predictor_filename=files_with_subset[1], import_strategy='lazy').combinedData.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from os import remove\n",
                "[remove(file) for file in [*files_with_subset, *files_without_subset]]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This +- 2x increase in speed will be even more significant as we increase the size of the data. \n",
                "\n",
                "## Lazy vs Eager\n",
                "As mentioned before, however, the default mode of reading is `\"eager\"`. This still allows us to use the previously mentioned execution graph, but the difference is in what we do after we do all of this preprocessing, right before returning the ADMDatamart class: `.collect().lazy()`. Opening up `modelData` in `eager` mode shows that we don't have a graph anymore:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "modd = datasets.CDHSample().modelData\n",
                "print(type(modd))\n",
                "modd.show_graph()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The type of `modelData` is a `LazyFrame` (the representation of this being a query plan). `DataFrame` and `LazyFrame`s are not so different - `LazyFrame`s build up a query and want you to execute once it's done, `DataFrame`s execute each command as you're calling it. However, in `eager` mode, that execution graph is empty.\n",
                "\n",
                "That leads to the fundamental difference between the `import_strategy` keyword argument:\n",
                "- In `lazy` mode - we only build the execution graph, but we rather than _reading_ the data, we only _scan_ it\n",
                "- In `eager` mode - we build the execution graph and execute it, _reading_ all data into memory. This means we don't have to execute that graph everytime we call it.\n",
                "\n",
                "The `eager` mode stil maintains `LazyFrame`s for both `modelData` and `predictorData`, but those tables are now not stored on disk anymore, but kept in memory. Any subsequent operations will build up a new execution graph, only executed when calling `.collect()`.\n",
                "\n",
                "### When to use which?\n",
                "By default, we use `eager` mode. We recommend using that, unless:\n",
                "\n",
                "- Your data is too big to fit into memory\n",
                "- You're using just one plot\n",
                "\n",
                "In all other cases, it's probably fine to just use eager mode, _unless_.\n",
                "\n",
                "## File Types\n",
                "\n",
                "Pega's default export format is to return a zip file, in which is a `data.json` file, which is in newline-delimited json format. While this is a decent storage format, it doesn't allow for any scanning operations because we need to open the entire zip into memory before being able to read anything. Therefore, if you're using the default export format, we set the import strategy to eager. If you're working with very large files and you need faster processing, it may be worth it to unzip the files, or even transform them to Arrow/IPC (fastest) or Parquet (most efficient). Then, you can use lazy mode, and can process files larger than memory as an added benefit.\n",
                "\n",
                "\n",
                "## Further Polars examples\n",
                "\n",
                "To help you get adjusted to this new syntax, let's go over a few more examples.\n",
                "\n",
                "The regular facets syntax still works, and can be combined with the new querying syntax."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm = datasets.CDHSample()\n",
                "\n",
                "dm.plotPerformanceSuccessRateBubbleChart(\n",
                "    query=pl.col(\"Issue\") == \"Sales\", facets=[\"Channel\"]\n",
                ")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "However, if you want to _combine_ queries, let's say just looking at Sales/Web, the best way to do that is like this (also note the extra brackets between expressions):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.plotPerformanceSuccessRateBubbleChart(\n",
                "    query=(pl.col(\"Issue\") == \"Sales\") & (pl.col(\"Channel\") == \"Web\")\n",
                ")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can make use of string operations (hover to verify for yourself!):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.plotPerformanceSuccessRateBubbleChart(\n",
                "    query=(pl.col(\"Name\").str.starts_with(\"Premier\"))\n",
                "    | (pl.col(\"Name\").str.ends_with(\"Gold\"))\n",
                ")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Since we have full access to Polar's expressions, we can use a [very wide range of functions](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/index.html), including windowing, folds, and slices. \n",
                "\n",
                "For something more advanced: let's look at the highest performance model per group."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.plotPerformanceSuccessRateBubbleChart(\n",
                "    query=(pl.col(\"Performance\") == pl.max(\"Performance\")).over(\"Group\")\n",
                ")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Or we can look at temporal filters, like only looking at the first snapshot:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm.plotPerformanceSuccessRateBubbleChart(query=pl.col('SnapshotTime')==pl.col('SnapshotTime').min())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
