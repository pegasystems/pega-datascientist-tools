---
title: "thompson-sampling-explained"
author: "Pega"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{thompson-sampling-explained}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
# knitr options: https://yihui.name/knitr/options/
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 7,
  fig.height = 5,
  fig.align = "center",
  comment = "#>"
)

library(ggplot2)
library(scales)
library(colorspace)
library(tidyverse)
library(data.table)

theme_set(theme_bw())

set.seed(1966)
```


# Thompson Sampling

Pega Customer Decision Hub uses a mechanism called Thompson Sampling, which is a method to sample the propensities from a distribution that centers around the model propensity. The width of the distribution depends on the evidence the model has seen. For new actions the propensities are random between 0 and 1. When the model gathers more evidence, the sampled propensities get closer to the model propensities.

This mechanism helps in a few different ways. For outbound channels, when multiple new actions are launched, they will all have the 
same 0.5 propensity (that is where a new model starts). Thompson Sampling effectively adds a bit of noise so it is not always the same
new action that gets selected. For both inbound and outbound channels, Thompson Sampling helps to add some extra "exploration" to the
models in the early phases.

See also:

* https://en.wikipedia.org/wiki/Thompson_sampling
* https://docs.pega.com/pega-customer-decision-hub-user-guide/87/model-learning-new-actions.

```{r include=FALSE}
createSamples <- function(settings)
{
  rbindlist(apply(settings, 1, function(setting) { 
    names(setting) <- names(settings)
    data.table( n = setting["n"],
                p = setting["p"],
                evidence = setting["evidence"],
                sampled_propensity = rbeta(setting["n"], setting["p"]*setting["evidence"], (1-setting["p"])*setting["evidence"])) }))  
}
```

## Spread of the Thompson Sampled propensities

The following plot shows how the spread of sampled propensities narrows with more responses
received by the models. We show simulated results for a few different model propensities.

```{r echo=FALSE, message=F, warning=F}
settingsShowTSSpread <- list(n = 5,
                             p = c(0.1, 0.05, 0.01),
                             positives = seq(0,1000)) %>%
  cross_df() %>% as.data.table()
settingsShowTSSpread[, evidence := positives/p]

thompsonSamplingSimulation <- createSamples(settingsShowTSSpread)
thompsonSamplingSimulation[, positives := evidence*p]

ggplot(thompsonSamplingSimulation, aes(positives, sampled_propensity, color=factor(p, levels=unique(settingsShowTSSpread$p)))) +
  geom_point(alpha=0.6, size=0.3) +
  xlab("Number of positive responses in the Adaptive Model") +
  scale_color_discrete_qualitative (name = "Model Propensity", guide = "none") +
  scale_y_continuous(labels = scales::percent_format(), name="Sampled Propensity", 
                     limits=c(0,0.2), breaks = c(0, unique(settingsShowTSSpread$p), 0.2)) +
  geom_label(mapping =  aes(x=x, y=p+0.01, label=sprintf("Propensity = %.2f%%", 100*p)), 
             data = settingsShowTSSpread[, .(x=50), by=p], hjust = 0, size=3) +
  ggtitle("Thompson Sampling") 
```


## Convergence of the Thompson Sampled propensities

To illustrate the fact that the Thompson Sampled propensities quickly converge
to the model propensities, below plot shows the percentage of sampled propensities
that are within 10% of the original model propensity.

For new models (no responses) that is around 50% but at about 200 positive
responses, around 90% of the sampled propensities are within 10% of the 
original model propensities. After 500 positive responses almost all of the
sampled propensities are within that range.

The colors indicate the same base propensities as before, but as can be 
seen, the convergence rate is independent of the base propensities.

```{r echo=FALSE}
thompsonSamplingSimulation[, bin := cut(positives, 50)]
s <- thompsonSamplingSimulation[, .(n = .N, n90 = sum(((sampled_propensity - p)/p) < 0.1), positives = min(positives)) , by=c("p", "bin")]
s[, pct := n90/n]
s[, p := factor(p, levels=unique(settingsShowTSSpread$p))]

ggplot(s, aes(positives, pct, color=p, group=p)) + 
  geom_line() +
  scale_color_discrete_qualitative (name = "Model Propensity", guide = "none") +
  scale_y_continuous(labels = scales::percent_format(), name="Percentage") +
  xlab("Number of positive responses in the Adaptive Model") +
  geom_vline(xintercept=200, linetype="dashed") +
  ggtitle("Percentage of Sampled Propensities", subtitle = "that are within 10% of the Model Propensities")
```


## Beta distribution

In principle, Thompson Sampling is based on the $\beta$-distribution (https://en.wikipedia.org/wiki/Beta_distribution) with "positive" and "negative" responses as the shape parameters. 

But for practical reasons, instead of using $\beta(positives, negatives)$, we approximate this with $\beta(p*evidence, (1-p)*evidence)$.

### Using Positives directly

With https://agilestudio.pega.com/prweb/AgileStudio/app/agilestudio/bugs/BUG-803575 we will
change the implementation in NBAD to use the positives directly so it will become $p + \beta(positives, negatives) - \frac{positives}{evidence}$ with $evidence = positives + negatives$.

### Visualization of Thompson Sampling

Here we show the distribution for a few combinations of model propensity and evidence. Note that the distributions
do not have their top at exactly the model propensity. This is because the beta distribution gives values in the
range 0..1 so for the (typical) small propensity values, the distribution is somewhat right-tailed.


```{r echo=FALSE}
settings1 <- data.table(
  n = 100000,
  p = c(0.01, 0.05, 0.1),
  evidence = c(2000, 200, 100000),
  ypeak = c(200, 50, 500)
)

ggplot(createSamples(settings1), 
       aes(sampled_propensity, fill=as.factor(evidence*p))) +
  geom_density(alpha=0.3) +
  scale_x_continuous(labels = scales::percent_format(), name="Sampled Propensity", breaks = c(0, unique(settings1$p))) +
  scale_fill_discrete_qualitative (name = "Positives", guide = "none") +
  scale_color_discrete_qualitative (name = "Model Propensity") +
  geom_vline(aes(xintercept = p), linetype="dashed", alpha=0.5) +
  ggtitle("Distribution of the sampled propensities", subtitle = "for a few combinations of model propensity and evidence")+
  geom_label(mapping = aes(x=p, y=ypeak, label=sprintf("Propensity = %.2f%%\nPositives = %d", 100*p, evidence*p)),
             data = settings1, hjust = 0.5, vjust = 0, fill = "white", size = 3) +
  theme(axis.text.y=element_blank(), axis.title.y=element_blank())
```



# Outbound Model Maturity

Thompson Sampling is related to the concept of Outbound Model Maturity. In outbound
channels, we limit the reach of new actions to avoid sending too many actions
"blindly" to customers. As more feedback is accumulated, the percentage of
the customers that can receive the new actions is increased.

We start with 2% of the population for new actions and scale that linearly to
100% until we reach a threshold of 200 positive responses. This is illustrated
by the following plot:

```{r echo=FALSE}
ommdata <- data.table( positives = c(0, 200, 300),
                       modelMaturityBasedReach = c(0.02, 1.0, 1.0))

ggplot(ommdata, aes(positives, modelMaturityBasedReach)) +
  geom_line(color="blue", size=1) +
  scale_y_continuous(labels = scales::percent_format(), name="% Selected from Eligible Customers", breaks=sort(c(seq(0.25,1,by=.25), 0.02))) +
  xlab("Number of Positives in the Adaptive Model") +
  annotate("label", x = 30, y = 0.05, label = "New\nActions", color="darkgreen", size = 3) +
  annotate("label", x = 240, y = 0.90, label = "Actions with\nMatured Models", color="darkgreen", size = 3) +
  ggtitle("Outbound Model Maturity")
```

## Effect when introducing new actions

```{r echo=FALSE}
nInitialActions <- 5
basePropensity <- 0.01
ncust <- 100000L
```

Suppose we start with 5 actions and introduce a new action every week. We
receive feedback after a week, so the reach of the new
actions ramps up after each week until it reaches the 200 positives and is then
mixed with the other actions.

The plot below illustrates how many customers (out of a hypothetical base
of `r ncust`) get the different actions.

Of course, in an actual implementation, there usually are more factors that are 
considered whether or not to give an action. This includes volume constraints,
propensity thresholding and other factors.

```{r echo=FALSE}
simulateActions <- function(initialActions)
{
  actions <- initialActions
  
  for (w in 0:10) {
    if (w > 0) {
      # add a new action every week
      
      newWeek <- rbindlist(list(copy(actions[week == w-1]), 
                                data.table(action = LETTERS[nInitialActions+w], 
                                           basepropensity = basePropensity, evidence = 0, week = w)), 
                           use.names = T, fill = T)
      newWeek[, week := w]
      
      actions <- rbindlist(list(copy(actions), newWeek))
    }
    
    actions[, positives := evidence * basepropensity]
    actions[, modelMaturityBasedReach := ifelse(positives >= 200, 1.0, 0.02 + 0.98*(positives/200))]
    
    # actions[, modelMaturityBasedReach := modelMaturityBasedReach*(1.0 + runif(.N)*0.1)]
    
    # simulating the situation where each of the ncust customers gets 1 action
    
    actions[week==w, expectedaccepts := ncust*modelMaturityBasedReach*basepropensity]
    actions[week==w, impressions := ncust*modelMaturityBasedReach]
    actions[week==w, impressions := impressions * min(1.0, (ncust / sum(impressions)))]
    
    # actions[week==w, impressions := ncust*expectedaccepts/(sum(expectedaccepts))] # roulette wheel
    
    if (w>0) {
      for (names in actions[week==w]$action) {
        actions[action == names & week == w, evidence := c(actions[action == names & week == w-1]$evidence, 0)[1] + 
                  c(actions[action == names & week == w-1]$impressions, 0)[1] ]
      }
    }
  }
  
  actions[, week := factor(week)]
  
  return(actions)
}

actions <- simulateActions(
  data.table(
    action = LETTERS[1:nInitialActions],
    basepropensity = rnorm(nInitialActions, basePropensity, 0.001),
    evidence = trunc(runif(nInitialActions, 15000, 40000)),
    week = 0
  )
)

ggplot(actions, aes(week, impressions, fill=action, group=action)) + 
  geom_area(color="black") +
  scale_fill_discrete_diverging() +
  ylab("Number of Customers") +
  ggtitle("Effect of Outbound Model Maturity", subtitle = "when introducing weekly new actions")
```

## Effect on all new actions

If at day zero all actions are new, it depends on the amount of available
actions.

If there are sufficient actions, then all customers may receive one, but
the targeting will not be very personalized. The distribution will still look even.

If there are few actions, then the model maturity capping may have the effect
that initially not everyone will get an action. As the models mature and become
more targeted, this will change.

```{r echo=FALSE}
actions <- simulateActions(
  data.table(
    action = LETTERS[1:nInitialActions],
    basepropensity = rnorm(nInitialActions, basePropensity, 0.001),
    evidence = 0,
    week = 0
  )
)

ggplot(actions, aes(week, impressions, fill=action, group=action)) + 
  geom_area(color="black") +
  scale_fill_discrete_diverging() +
  ylab("Number of Customers") +
  ggtitle("Effect of Outbound Model Maturity", subtitle = "when introducing weekly new actions")

```

