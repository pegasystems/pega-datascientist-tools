{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RABO AGB Model Analysis\n",
    "\n",
    "Analysis of all exported AGB models from the RABO AGB Adoption folder.\n",
    "There are 4 distinct models across two channels:\n",
    "- **Outbound (Email):** BE_Email, PA_Email\n",
    "- **Inbound (RBB/RBO):** BE_RBB, PA_RBO\n",
    "\n",
    "Each model has multiple weekly snapshots over time.\n",
    "\n",
    "This notebook:\n",
    "1. Loads all exported JSON files and creates `ADMTreesModel` objects\n",
    "2. Extracts CDH_ADM005-style metrics from each model via the `.metrics` property\n",
    "3. Plots all metric trends over time per model, with Inbound/Outbound visually distinguished\n",
    "4. Shows `tree_stats` for one model as an example\n",
    "\n",
    "**Reference:** Pega CDH_ADM005 telemetry event specification (see Pega platform documentation).\n",
    "\n",
    "**HTML export** (with interactive Plotly charts):\n",
    "```bash\n",
    "uv run python -m ipykernel install --user --name pega-datascientist-tools  # one-time setup\n",
    "PLOTLY_RENDERER=notebook uv run python -m jupyter nbconvert --to html --execute --no-input \\\n",
    "  --ExecutePreprocessor.kernel_name=pega-datascientist-tools \\\n",
    "  examples/adm/RABO_AGB_Model_Analysis.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from pdstools.adm.ADMTrees import ADMTreesModel\n",
    "\n",
    "# For HTML export, set PLOTLY_RENDERER=notebook before running nbconvert.\n",
    "# In VS Code, leave unset for native rendering.\n",
    "if os.environ.get(\"PLOTLY_RENDERER\"):\n",
    "    pio.renderers.default = os.environ[\"PLOTLY_RENDERER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover and load all exported model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = (\n",
    "    Path.home()\n",
    "    / \"Library/CloudStorage/OneDrive-PegasystemsInc\"\n",
    "    / \"PRD - 1-1 Customer Engagement Alliance - Machine Learning\"\n",
    "    / \"EasyPz/Adaptive gradient boosting/RABO AGB Adoption/Exported RABO GB models\"\n",
    ")\n",
    "\n",
    "json_files = sorted(models_dir.glob(\"export_*.json\"))\n",
    "print(f\"Found {len(json_files)} exported model files\")\n",
    "for f in json_files[:3]:\n",
    "    print(f\"  {f.name}\")\n",
    "print(f\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all models and extract metrics\n",
    "\n",
    "For each JSON file, create an `ADMTreesModel` object and call `.metrics` to get\n",
    "CDH_ADM005-style diagnostic metrics. The model name and timestamp are parsed from\n",
    "the filename. A **channel** column is derived: Email models → Outbound, RBB/RBO → Inbound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern: export_<MODEL_NAME>_<TIMESTAMP>.json\n",
    "filename_pattern = re.compile(r\"^export_(.+)_(\\d{8}T\\d{6})\\.json$\")\n",
    "\n",
    "records = []\n",
    "first_trees = {}  # store first tree object per model for example below\n",
    "\n",
    "for fp in json_files:\n",
    "    m = filename_pattern.match(fp.name)\n",
    "    if not m:\n",
    "        print(f\"Skipping {fp.name} - does not match expected pattern\")\n",
    "        continue\n",
    "    model_name = m.group(1)\n",
    "\n",
    "    trees = ADMTreesModel(str(fp))\n",
    "    metrics = trees.metrics\n",
    "    metrics[\"model_name\"] = model_name\n",
    "    metrics[\"file_name\"] = fp.name\n",
    "    records.append(metrics)\n",
    "\n",
    "    if model_name not in first_trees:\n",
    "        first_trees[model_name] = trees\n",
    "\n",
    "df = (\n",
    "    pl.DataFrame(records)\n",
    "    .with_columns(\n",
    "        pl.col(\"factory_update_time\")\n",
    "        .str.to_datetime(\"%Y-%m-%dT%H:%M:%S%.fZ\")\n",
    "        .alias(\"snapshot_time\"),\n",
    "        # Classify channel: Email = Outbound, RBB/RBO = Inbound\n",
    "        pl.when(pl.col(\"model_name\").str.contains(\"Email\"))\n",
    "        .then(pl.lit(\"Outbound (Email)\"))\n",
    "        .otherwise(pl.lit(\"Inbound (RBB/RBO)\"))\n",
    "        .alias(\"channel\"),\n",
    "    )\n",
    "    .sort(\"model_name\", \"snapshot_time\")\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(df)} model snapshots across {df['model_name'].n_unique()} models\")\n",
    "print(f\"Models: {df['model_name'].unique().sort().to_list()}\")\n",
    "print(f\"Channels: {df['channel'].unique().sort().to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    \"model_name\",\n",
    "    \"channel\",\n",
    "    \"snapshot_time\",\n",
    "    \"auc\",\n",
    "    \"success_rate\",\n",
    "    \"number_of_trees\",\n",
    "    \"number_of_tree_nodes\",\n",
    "    \"total_number_of_active_predictors\",\n",
    "    \"response_positive_count\",\n",
    "    \"response_negative_count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric trend plots\n",
    "\n",
    "Plot all numeric CDH_ADM005 metrics over time, grouped by model.\n",
    "- **Solid lines** = Inbound (RBB/RBO)\n",
    "- **Dashed lines** = Outbound (Email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify plottable metric columns (numeric, non-null, non-id)\n",
    "exclude = {\"model_name\", \"file_name\", \"snapshot_time\", \"factory_update_time\", \"channel\"}\n",
    "metric_cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in exclude and df[c].dtype in (pl.Float64, pl.Int64, pl.UInt32)\n",
    "]\n",
    "print(f\"Plotting {len(metric_cols)} metrics: {metric_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt into long format for faceted plotting\n",
    "df_long = df.select(\n",
    "    \"model_name\", \"channel\", \"snapshot_time\", *metric_cols\n",
    ").unpivot(\n",
    "    index=[\"model_name\", \"channel\", \"snapshot_time\"],\n",
    "    on=metric_cols,\n",
    "    variable_name=\"metric\",\n",
    "    value_name=\"value\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group metrics by category for cleaner plots\n",
    "metric_groups = {\n",
    "    \"Model Performance\": [\"auc\", \"success_rate\"],\n",
    "    \"Data Quality\": [\"response_positive_count\", \"response_negative_count\"],\n",
    "    \"Model Complexity\": [\n",
    "        \"number_of_trees\",\n",
    "        \"number_of_tree_nodes\",\n",
    "        \"tree_depth_max\",\n",
    "        \"tree_depth_avg\",\n",
    "        \"tree_depth_std\",\n",
    "        \"number_of_stump_trees\",\n",
    "        \"avg_leaves_per_tree\",\n",
    "    ],\n",
    "    \"Splits by Predictor Type\": [\n",
    "        \"number_of_splits_on_ih_predictors\",\n",
    "        \"number_of_splits_on_context_key_predictors\",\n",
    "        \"number_of_splits_on_other_predictors\",\n",
    "    ],\n",
    "    \"Predictor Counts\": [\n",
    "        \"total_number_of_active_predictors\",\n",
    "        \"total_number_of_predictors\",\n",
    "        \"number_of_active_ih_predictors\",\n",
    "        \"total_number_of_ih_predictors\",\n",
    "        \"number_of_active_context_key_predictors\",\n",
    "    ],\n",
    "    \"Predictor Types\": [\n",
    "        \"number_of_active_symbolic_predictors\",\n",
    "        \"total_number_of_symbolic_predictors\",\n",
    "        \"number_of_active_numeric_predictors\",\n",
    "        \"total_number_of_numeric_predictors\",\n",
    "    ],\n",
    "    \"Gain Distribution\": [\n",
    "        \"total_gain\",\n",
    "        \"mean_gain_per_split\",\n",
    "        \"median_gain_per_split\",\n",
    "        \"max_gain_per_split\",\n",
    "        \"gain_std\",\n",
    "    ],\n",
    "    \"Leaf Scores\": [\n",
    "        \"number_of_leaves\",\n",
    "        \"leaf_score_mean\",\n",
    "        \"leaf_score_std\",\n",
    "        \"leaf_score_min\",\n",
    "        \"leaf_score_max\",\n",
    "    ],\n",
    "    \"Split Types\": [\n",
    "        \"number_of_numeric_splits\",\n",
    "        \"number_of_symbolic_splits\",\n",
    "        \"symbolic_split_fraction\",\n",
    "        \"number_of_unique_splits\",\n",
    "        \"split_reuse_ratio\",\n",
    "        \"avg_symbolic_set_size\",\n",
    "    ],\n",
    "    \"Learning Convergence\": [\n",
    "        \"mean_abs_score_first_10\",\n",
    "        \"mean_abs_score_last_10\",\n",
    "        \"score_decay_ratio\",\n",
    "        \"mean_gain_first_half\",\n",
    "        \"mean_gain_last_half\",\n",
    "    ],\n",
    "    \"Feature Importance Concentration\": [\n",
    "        \"top_predictor_gain_share\",\n",
    "        \"predictor_gain_entropy\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Load metric descriptions from the library\n",
    "from IPython.display import display, Markdown\n",
    "descriptions = ADMTreesModel.metric_descriptions()\n",
    "\n",
    "for group_name, cols in metric_groups.items():\n",
    "    available = [c for c in cols if c in metric_cols]\n",
    "    if not available:\n",
    "        continue\n",
    "    for metric_name in available:\n",
    "        desc = descriptions.get(metric_name, \"\")\n",
    "        display(Markdown(f\"**{metric_name.replace('_', ' ').title()}** — {desc}\"))\n",
    "        subset = df_long.filter(pl.col(\"metric\") == metric_name)\n",
    "        title = f\"{group_name}: {metric_name.replace('_', ' ')}\"\n",
    "        fig = px.line(\n",
    "            subset.to_pandas(),\n",
    "            x=\"snapshot_time\",\n",
    "            y=\"value\",\n",
    "            color=\"model_name\",\n",
    "            line_dash=\"channel\",\n",
    "            markers=True,\n",
    "            title=title,\n",
    "            labels={\"snapshot_time\": \"Snapshot Time\", \"value\": metric_name.replace('_', ' '), \"model_name\": \"Model\"},\n",
    "            template=\"none\",\n",
    "            category_orders={\"channel\": [\"Inbound (RBB/RBO)\", \"Outbound (Email)\"]},\n",
    "        )\n",
    "        fig.update_layout(height=350)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual metric: AUC over time\n",
    "\n",
    "Solid = Inbound, Dashed = Outbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    df.to_pandas(),\n",
    "    x=\"snapshot_time\",\n",
    "    y=\"auc\",\n",
    "    color=\"model_name\",\n",
    "    line_dash=\"channel\",\n",
    "    markers=True,\n",
    "    title=\"AUC over time per model\",\n",
    "    labels={\"snapshot_time\": \"Snapshot Time\", \"auc\": \"AUC\", \"model_name\": \"Model\"},\n",
    "    template=\"none\",\n",
    "    category_orders={\"channel\": [\"Inbound (RBB/RBO)\", \"Outbound (Email)\"]},\n",
    ")\n",
    "fig.update_yaxes(range=[0.5, 1.0])\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Tree statistics for the first model\n",
    "\n",
    "Show `tree_stats` for the first snapshot of the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_name = sorted(first_trees.keys())[0]\n",
    "example_trees = first_trees[first_model_name]\n",
    "\n",
    "print(f\"Model: {first_model_name}\")\n",
    "print(f\"Number of trees: {len(example_trees.model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_trees.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_trees.tree_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pega-datascientist-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
