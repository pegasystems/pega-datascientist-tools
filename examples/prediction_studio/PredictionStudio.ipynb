{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Studio Python library\n",
    "\n",
    "To get started, first we initialise an Infinity client.\n",
    "\n",
    "The user credentials are already set as environment variables so they will be automatically picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdstools import Infinity\n",
    "from dotenv import load_dotenv\n",
    "import polars as pl\n",
    "\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Infinity.from_basic_auth(\n",
    "    verify=False,\n",
    "    pega_version=\"24.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Prediction Studio & Monitoring APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Repository Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.prediction_studio.repository()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting notifications for a Prediction  Studio\n",
    "\n",
    "In Prediction Studio, we have notifications as a mechanism to stay up-to-date on any sudden or gradual changes in Prediction Studio Performance.\n",
    "\n",
    "These are also accessible through the APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notification = client.prediction_studio.get_notifications(return_df=True)\n",
    "notification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Predictions from Prediction Studio\n",
    "\n",
    "Use list_predictions to get a list of the Predictions in the system. \n",
    "\n",
    "Here we use `return_df` to get a nice tabular overview, but you can of course get the individual Prediction objects in the `predictions` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = client.prediction_studio.list_predictions(return_df=True)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing a single Prediction\n",
    "\n",
    "If we want to get more information about an individual Prediction, we can call `.describe()` on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = client.prediction_studio.get_prediction(label=\"Predict Web Propensity\")\n",
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Prediction metrics\n",
    "\n",
    "We can also plot the metrics corresponding to the Prediction by using `plot_metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "prediction = client.prediction_studio.get_prediction(label=\"Predict Cards Acceptance\")\n",
    "prediction.get_metric(start_date=date(2024,7,2), end_date=date(2024,7,11),\n",
    "                        metric=\"Lift\",\n",
    "                        frequency=\"Daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting notifications for a Prediction\n",
    "\n",
    "In Prediction Studio, we have notifications as a mechanism to stay up-to-date on any sudden or gradual changes in Prediction performance.\n",
    "\n",
    "These are also accessible through the APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_action_propensity = client.prediction_studio.get_prediction(label=\"Predict Action Propensity\")\n",
    "notification = Predict_action_propensity.get_notifications(return_df=True)\n",
    "notification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of models from Prediction Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.prediction_studio.list_models(return_df=True)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.prediction_studio.get_model(model_id=\"DATA-DECISION-REQUEST-CUSTOMER!OMNIADAPTIVEMODEL\")\n",
    "model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting notifications for a Model\n",
    "\n",
    "In Prediction Studio, we have notifications as a mechanism to stay up-to-date on any sudden or gradual changes in Model performance.\n",
    "\n",
    "These are also accessible through the APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notification = model.get_notifications(return_df=True)\n",
    "notification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger ADM datamart export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart_export1 = client.prediction_studio.trigger_datamart_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart_export1.get_export_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and model management APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Champion challenger objects of a prediction\n",
    "To perform any operation with the Prediction Studio library, we need champion-challenger models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = client.prediction_studio.get_prediction(label=\"Predict Cards Acceptance\")\n",
    "prediction.get_champion_challengers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel_falcons = client.prediction_studio.get_model(label=\"testModel_falcons\")\n",
    "testModel_falcons.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a conditional model to the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model category information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = client.prediction_studio.get_model_categories()\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retention_CC = prediction.add_conditional_model(new_model=testModel_falcons,category=\"Retention\")\n",
    "Retention_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retention_CC.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring further details about this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retention_CC.active_model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new adm challenger model to that champion challenger object by copying the active model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdstools.infinity.resources.prediction_studio.types import AdmModelType\n",
    "Retention_CC.clone_model(challenger_response_share=0.8, adm_model_type=AdmModelType.GRADIENT_BOOSTING, model_label=\"Test_model_1\")\n",
    "Retention_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retention_CC.challenger_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retention_CC.add_predictor(is_active_model=False, name=\"Income4\", parameterized=True, predictor_type=\"Numeric\", data_type=\"Double\",value=\"Customer.Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retention_CC.challenger_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retention_CC.remove_predictor(is_active_model=False, name=\"Income4\", parameterized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce a new challenger model to a active model from the Prediction Studio's available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.get_champion_challengers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoContext_CC = prediction.get_champion_challengers()[2]\n",
    "NoContext_CC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the available models for use in the Champion-Challenger setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoContext_CC.list_available_models_to_add(return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = client.prediction_studio.get_model(label=\"Test_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoContext_CC.add_model(new_model=test_model, challenger_response_share=0.8)\n",
    "NoContext_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoContext_CC.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoContext_CC.challenger_model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate a PMML model stored locally as a challenger in the Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdstools.infinity.resources.prediction_studio.local_model_utils import PMMLModel\n",
    "pmml_model = PMMLModel(file_path=\"riskModel.pmml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy model to repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_risk_model = client.prediction_studio.upload_model(pmml_model, file_name=\"riskModel.pmml\")\n",
    "new_risk_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.get_champion_challengers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskModel_cc = prediction.get_champion_challengers()[2]\n",
    "RiskModel_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskModel_cc.active_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_mapping = [\n",
    "    {\n",
    "      \"predictor\": \"Gender\",\n",
    "      \"property\": \".Gender\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"DataUsage\",\n",
    "      \"property\": \".RiskCode\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"Age\",\n",
    "      \"property\": \".Age\"\n",
    "    }]\n",
    "RiskModel_cc.add_model(new_model=new_risk_model, challenger_response_share=0.6,predictor_mapping=predictor_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskModel_cc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update champion challenger percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskModel_cc.update_challenger_response_share(new_challenger_response_share=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskModel_cc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promote the challenger model to active model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskModel_cc.promote_challenger_model()\n",
    "RiskModel_cc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the challenger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskModel_cc.delete_challenger_model()\n",
    "RiskModel_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all the Prediction Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.get_staged_changes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the staged changes for CR creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.deploy_staged_changes(message=\"Deploying demo changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, validate, run and upload ONNX model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Sklearn pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pathlib\n",
    "\n",
    "basePath = pathlib.Path().resolve().parent.parent\n",
    "file_path = f\"{basePath}/data/Churn_CID.csv\"\n",
    "dataset = pl.read_csv(file_path)\n",
    "X = dataset.select(dataset.columns[:-2])\n",
    "Y = dataset['outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "categorical_cols = X.select(pl.col(pl.String),pl.col(pl.Boolean)).columns\n",
    "numerical_cols = X.select(pl.col(pl.Int64), pl.col(pl.Float64)).columns\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the model input definitions (initial_types)\n",
    "(Note: Required for converting the pipeline object to ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "\n",
    "initial_types = [(col, FloatTensorType([None, 1])) for col in numerical_cols]\n",
    "initial_types.extend([(col, StringTensorType([None, 1])) for col in categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ONNX model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdstools.infinity.resources.prediction_studio.local_model_utils import ONNXModel\n",
    "onnx_model = ONNXModel.from_sklearn_pipeline(clf, initial_types=initial_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the output nodes of created onnx model, like label node and score node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netron\n",
    "import IPython\n",
    "import tempfile\n",
    "temp_file = tempfile.NamedTemporaryFile(suffix=\".onnx\")\n",
    "onnx_model.save(temp_file.name)\n",
    "netron.start(temp_file.name, browse=False)\n",
    "iframe = '<iframe src=\"http://localhost:8080\" width=\"100%\" height=\"600px\"></iframe>'\n",
    "IPython.display.HTML(iframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add metadata to ONNX model, use previously identified output nodes to populate labelName and scoreName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdstools.infinity.resources.prediction_studio.local_model_utils import Metadata, Output, OutcomeType\n",
    "onnx_model.add_metadata(Metadata(type=OutcomeType.BINARY, output=Output(label_name=\"output_label\",score_name=\"output_probability\", possible_values=[\"Churned\",\"Loyal\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test data and do a test run of ONNX model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action: cast numeric columns to float32 and string or bool columns to utf8\n",
    "# Reason: model was converted with float32 and utf8 for numeric and string or bool columns respectively\n",
    "test_df=pl.DataFrame(X_test, schema=X.columns).with_columns([\n",
    "    pl.col(col).cast(pl.Float32) if X[col].dtype in [pl.Int64, pl.Float64, pl.Int32, pl.Float32] else pl.col(col).cast(pl.Utf8)\n",
    "    for col in X.columns\n",
    "])\n",
    "# reshape each column to a 2D array\n",
    "test_data = {col: test_df[col].to_numpy().reshape(-1, 1) for col in test_df.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model.run(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline_model = client.prediction_studio.upload_model(onnx_model, file_name=\"churn_model.onnx\")\n",
    "new_pipeline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Prediction and do Champion Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = client.prediction_studio.get_prediction(label=\"Churn Risk\")\n",
    "prediction.get_champion_challengers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA-DECISION-REQUEST-CUSTOMER!CHURNRISK\n",
    "champion_challenger = prediction.get_champion_challengers()[0]\n",
    "champion_challenger.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_mapping = [\n",
    "    {\n",
    "      \"predictor\": \"InCollections\",\n",
    "      \"property\": \".Customer.InCollections\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"CreditScore\",\n",
    "      \"property\": \".Customer.CreditScore\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"Age\",\n",
    "      \"property\": \".Customer.Age\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"WinScore\",\n",
    "      \"property\": \".Customer.WinScore\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"RiskCode\",\n",
    "      \"property\": \".Customer.RiskCode\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"AnnualIncome\",\n",
    "      \"property\": \".Customer.AnnualIncome\"\n",
    "    },\n",
    "    {\n",
    "      \"predictor\": \"NetWealth\",\n",
    "      \"property\": \".Customer.NetWealth\"\n",
    "    }\n",
    "]\n",
    "champion_challenger.add_model(new_model=new_pipeline_model,challenger_response_share=0.8,predictor_mapping=predictor_mapping)\n",
    "champion_challenger.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pega-datascientist-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
